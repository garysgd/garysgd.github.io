<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-19T18:07:38+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">if: Learn</title><subtitle>Exploring Machine Learning and Theoretical Work | Gary Phua</subtitle><entry><title type="html">Reference Frames for Orbital Mechanics</title><link href="http://localhost:4000/space/2025/02/17/orbital-mechanics.html" rel="alternate" type="text/html" title="Reference Frames for Orbital Mechanics" /><published>2025-02-17T00:00:00+08:00</published><updated>2025-02-17T00:00:00+08:00</updated><id>http://localhost:4000/space/2025/02/17/orbital-mechanics</id><content type="html" xml:base="http://localhost:4000/space/2025/02/17/orbital-mechanics.html"><![CDATA[<p>In a simple two-body problem where two bodies have finite mass, their trajectories in space follow an elliptical orbit. When the mass of one body is much larger than that of the other, \(m_1 \gg m_2\), we can approximate the larger body as stationary while the smaller body orbits around it. The trajectory of the smaller body can be modeled with either the Keplerian or Cartesian reference frames, each offering its own advantages. The Cartesian reference frame is particularly useful for numerical calculations—such as computing future trajectories given the current state—while the Keplerian frame provides a more intuitive understanding of the orbit by describing its phase space in mathematical terms.</p>

<h4 id="cartesian-reference-frame">Cartesian Reference Frame</h4>
<p align="center">
  <img src="/images/orbit1.jpg" alt="Orbit Image" width="500" />
</p>

<p>This is the reference frame familiar to most people, defined by the position 
\(\vec{r} = [x, y, z]\) 
and velocity 
\(\vec{v} = [v_x, v_y, v_z].\)<br />
It is an inertial reference frame with the central (larger) body—typically Earth—at its point of reference. The Cartesian state vector is a six-dimensional vector formed by concatenating the position and velocity vectors:</p>

\[\vec{c} = [x, y, z, v_x, v_y, v_z].\]

<p>Together with the gravitational parameter \(\mu\), this state vector is sufficient to calculate the future trajectory of the object.</p>

<h4 id="keplerian-reference-frame">Keplerian Reference Frame</h4>
<p align="center">
  <img src="/images/orbit3.jpg" alt="Orbit Image" width="500" />
</p>

<p>In the Keplerian reference frame, an orbit is described not by instantaneous position and velocity components but by six <strong>orbital elements</strong> that capture the shape, size, orientation, and current position along the orbit. These six elements are:</p>

<ul>
  <li>
    <p><strong>Semimajor Axis,</strong> \(a\)<br />
Defines the size of the orbit—the average distance between the orbiting object and the central body.</p>
  </li>
  <li>
    <p><strong>Eccentricity,</strong> \(e\)<br />
Describes the shape of the orbit. An eccentricity of 0 corresponds to a circular orbit, while values between 0 and 1 indicate an elliptical orbit.</p>
  </li>
  <li>
    <p><strong>Inclination,</strong> \(i\)<br />
Represents the tilt of the orbital plane relative to a chosen reference plane (often the equatorial or ecliptic plane).</p>
  </li>
  <li>
    <p><strong>Right Ascension of the Ascending Node,</strong> \(\Omega\)<br />
The angle in the reference plane from a fixed direction (typically the vernal equinox) to the point where the orbiting body crosses the reference plane upward (the ascending node).</p>
  </li>
  <li>
    <p><strong>Argument of Periapsis,</strong> \(\omega\)<br />
Measured in the orbital plane, this angle specifies the direction of the closest approach (periapsis) relative to the ascending node.</p>
  </li>
  <li>
    <p><strong>True Anomaly,</strong> \(\nu\)<br />
Indicates the object’s current position along its orbit relative to the periapsis, measured in the orbital plane.</p>
  </li>
</ul>

<p>These elements combine to form the <strong>Keplerian state vector</strong>:</p>

\[\vec{k} = [\,a,\; e,\; i,\; \Omega,\; \omega,\; \nu\,].\]

<p>Together with the gravitational parameter \(\mu\), this six-element vector fully defines the orbit in the two-body problem. Although it does not directly include position and velocity components, these orbital elements encapsulate all the necessary information—through Kepler’s laws and the laws of motion—to compute the object’s future trajectory.</p>

<p>Given \(\vec{k}\) and \(\mu\), one can derive the instantaneous Cartesian state vector (and vice versa) using established transformation formulas. This makes the Keplerian state vector not only a compact representation of the orbit’s geometry but also sufficient for predicting the motion of the orbiting object over time.</p>

<h3 id="derivation-of-the-conic-section-orbit-equation-and-its-conversion-to-cartesian-coordinates">Derivation of the Conic Section Orbit Equation and Its Conversion to Cartesian Coordinates</h3>

<p>In orbital mechanics, the motion of a secondary body under the gravitational influence of a primary (central) body is governed by an inverse-square force. The resulting trajectory is a conic section (ellipse, parabola, or hyperbola). In the bound case (negative total energy), the orbit is an ellipse, and its shape and orientation can be described by six Keplerian orbital elements:</p>

\[\vec{k} = [\,a,\; e,\; i,\; \Omega,\; \omega,\; \nu\,],\]

<p>where:</p>
<ul>
  <li><strong>(a)</strong> is the semimajor axis (size of the orbit),</li>
  <li><strong>(e)</strong> is the eccentricity (shape of the orbit),</li>
  <li><strong>(i)</strong> is the inclination (tilt of the orbital plane),</li>
  <li><strong>(\Omega)</strong> is the right ascension of the ascending node (orientation of the line of nodes in the reference plane),</li>
  <li><strong>(\omega)</strong> is the argument of periapsis (angle from the ascending node to periapsis within the orbital plane),</li>
  <li><strong>(\nu)</strong> is the true anomaly (the current position along the orbit measured from periapsis).</li>
</ul>

<p>Together with the gravitational parameter \(\mu\), these elements fully define the orbit in a two-body problem. We now describe, step by step, how the conic orbit equation is derived and how the Keplerian state vector is converted into the Cartesian (inertial) state vector.</p>

<hr />

<h4 id="1-derivation-of-the-conic-section-orbit-equation">1. Derivation of the Conic Section Orbit Equation</h4>

<p><strong>a. Newton’s Equation of Motion</strong></p>

<p>For a body moving under the gravitational force of a central mass, Newton’s law gives:</p>

\[\ddot{\mathbf{r}} = -\frac{\mu}{r^3}\mathbf{r},\]

<p>where \(\mu = G(M+m)\) (often approximated as \(GM\) when \(M \gg m\)). In polar coordinates (with variables \(r\) and \(\theta\)), the position vector is</p>

\[\mathbf{r} = r\,\hat{\mathbf{r}}.\]

<p><strong>b. Conservation of Angular Momentum</strong></p>

<p>Angular momentum per unit mass is conserved:</p>

\[h = r^2 \dot{\theta} = \text{constant},\]

<p>which implies</p>

\[\dot{\theta} = \frac{h}{r^2}.\]

<p><strong>c. Substituting \(u = \frac{1}{r}\)</strong></p>

<p>Define the reciprocal variable:</p>

\[u(\theta) = \frac{1}{r}.\]

<p>Differentiating with respect to \(\theta\):</p>

<ul>
  <li>
    <p>The first derivative is</p>

\[\frac{dr}{d\theta} = -\frac{1}{u^2}\frac{du}{d\theta}.\]
  </li>
  <li>
    <p>The second derivative can be related to time derivatives by noting</p>

\[\ddot{r} = \frac{d^2r}{d\theta^2}\,\dot{\theta}^2.\]
  </li>
</ul>

<p>Substitute these into the radial component of Newton’s equation and use</p>

\[\dot{\theta} = h\,u^2.\]

<p>After some algebra, the radial equation reduces to the differential equation:</p>

\[\frac{d^2 u}{d\theta^2} + u = \frac{\mu}{h^2}.\]

<p><strong>d. Solving the Differential Equation</strong></p>

<p>This is a linear second-order differential equation with constant coefficients. Its general solution is:</p>

\[u(\theta) = A\cos(\theta - \theta_0) + \frac{\mu}{h^2},\]

<p>where \(A\) and \(\theta_0\) are constants determined by the initial conditions. By choosing the coordinate system so that \(\theta_0 = 0\) (i.e., measuring \(\theta\) from periapsis) and defining the eccentricity \(e\) via</p>

\[e = \frac{A h^2}{\mu},\]

<p>we can write:</p>

\[u(\theta) = \frac{\mu}{h^2}\left(1 + e\cos\theta\right).\]

<p>Since \(u = \frac{1}{r}\), the orbit equation becomes:</p>

\[r = \frac{h^2/\mu}{1 + e\cos\theta}.\]

<p>Defining the semi-latus rectum as</p>

\[p = \frac{h^2}{\mu},\]

<p>the polar equation of the orbit is:</p>

\[\boxed{r(\theta) = \frac{p}{1 + e\cos\theta}.}\]

<p><em>Interpretation:</em></p>
<ul>
  <li>For \(0 \le e &lt; 1\), the orbit is elliptical.</li>
  <li>For \(e = 0\), the orbit is circular.</li>
  <li>For \(e = 1\), the orbit is parabolic.</li>
  <li>For \(e &gt; 1\), the orbit is hyperbolic.</li>
</ul>

<hr />

<h4 id="2-converting-the-keplerian-elements-to-a-cartesian-state-vector">2. Converting the Keplerian Elements to a Cartesian State Vector</h4>

<p>Now that we have the orbit expressed in polar coordinates, we can derive the Cartesian position and velocity vectors.</p>

<p><strong>a. Position in the Perifocal (PQW) Frame</strong></p>

<p>In the orbital (PQW) frame, the x-axis (P-axis) points toward periapsis, and the y-axis (Q-axis) is perpendicular to it. Thus, the position vector is given by:</p>

\[\mathbf{r}_{PQW} = \begin{bmatrix} r\cos\nu \\ r\sin\nu \\ 0 \end{bmatrix},\]

<p>with</p>

\[r = \frac{a(1-e^2)}{1 + e\cos\nu}.\]

<p>Substitute to obtain:</p>

\[\mathbf{r}_{PQW} = 
\begin{bmatrix}
\displaystyle \frac{a(1-e^2)\cos\nu}{1 + e\cos\nu} \\[1mm]
\displaystyle \frac{a(1-e^2)\sin\nu}{1 + e\cos\nu} \\[1mm]
0
\end{bmatrix}.\]

<p><strong>b. Velocity in the Perifocal (PQW) Frame</strong></p>

<p>The velocity in polar coordinates has a radial component \(v_r = \dot{r}\) and a transverse component \(v_\theta = r\,\dot{\nu}\).</p>

<p>From conservation of angular momentum, we have:</p>

\[h = \sqrt{\mu\,a(1-e^2)} \quad \text{and} \quad \dot{\nu} = \frac{h}{r^2}.\]

<p>Differentiate the orbit equation with respect to \(\nu\):</p>

\[\frac{dr}{d\nu} = \frac{a(1-e^2)e\sin\nu}{(1+e\cos\nu)^2}.\]

<p>Then, applying the chain rule:</p>

\[v_r = \dot{r} = \frac{dr}{d\nu}\,\dot{\nu} 
= \frac{a(1-e^2)e\sin\nu}{(1+e\cos\nu)^2} \cdot \frac{h}{r^2}.\]

<p>Since</p>

\[r^2 = \frac{a^2(1-e^2)^2}{(1+e\cos\nu)^2},\]

<p>we simplify to:</p>

\[v_r = \frac{h\,e\sin\nu}{a(1-e^2)}.\]

<p>The transverse component is:</p>

\[v_\theta = r\,\dot{\nu} = \frac{h}{r} = \frac{h\,(1+e\cos\nu)}{a(1-e^2)}.\]

<p>The velocity vector in the PQW frame is then given by:</p>

\[\mathbf{v}_{PQW} = \begin{bmatrix}
v_r\cos\nu - v_\theta\sin\nu \\[1mm]
v_r\sin\nu + v_\theta\cos\nu \\[1mm]
0
\end{bmatrix}.\]

<p>After substituting the expressions for \(v_r\) and \(v_\theta\) and simplifying, we obtain the commonly used form:</p>

\[\mathbf{v}_{PQW} = 
\begin{bmatrix}
-\sqrt{\dfrac{\mu}{p}}\,\sin\nu \\[1mm]
\sqrt{\dfrac{\mu}{p}}\,(e+\cos\nu) \\[1mm]
0
\end{bmatrix},\]

<p>with \(p = a(1-e^2)\).</p>

<p><strong>c. Transforming from the Perifocal Frame to the Inertial (Cartesian) Frame</strong></p>

<p>To obtain the Cartesian state vector in an inertial frame (often Earth-Centered Inertial), we perform three successive rotations:</p>

<ol>
  <li>Rotate by \(-\omega\) about the z-axis.</li>
  <li>Rotate by \(-i\) about the x-axis.</li>
  <li>Rotate by \(-\Omega\) about the z-axis.</li>
</ol>

<p>The combined rotation matrix is given by:</p>

\[Q_{Xx} = R_z(-\Omega)\, R_x(-i)\, R_z(-\omega),\]

<p>or equivalently (depending on the chosen convention):</p>

\[Q_{Xx} =
\begin{bmatrix}
\cos\Omega\cos\omega - \sin\Omega\sin\omega\cos i &amp; -\cos\Omega\sin\omega - \sin\Omega\cos\omega\cos i &amp; \sin\Omega\sin i \\
\sin\Omega\cos\omega + \cos\Omega\sin\omega\cos i &amp; -\sin\Omega\sin\omega + \cos\Omega\cos\omega\cos i &amp; -\cos\Omega\sin i \\
\sin\omega\sin i &amp; \cos\omega\sin i &amp; \cos i 
\end{bmatrix}.\]

<p>Thus, the Cartesian position and velocity vectors are:</p>

\[\mathbf{r}_{ECI} = Q_{Xx}\,\mathbf{r}_{PQW},\]

\[\mathbf{v}_{ECI} = Q_{Xx}\,\mathbf{v}_{PQW}.\]

<hr />

<h4 id="5-summary">5. Summary</h4>

<ol>
  <li>
    <p><strong>Conic Section Orbit Equation:</strong></p>

\[r(\theta) = \frac{p}{1 + e\cos\theta}, \quad \text{with } p = \frac{h^2}{\mu}.\]
  </li>
  <li>
    <p><strong>Perifocal (PQW) Position:</strong></p>

\[\mathbf{r}_{PQW} = \begin{bmatrix}
\displaystyle \frac{a(1-e^2)\cos\nu}{1 + e\cos\nu} \\[1mm]
\displaystyle \frac{a(1-e^2)\sin\nu}{1 + e\cos\nu} \\[1mm]
0
\end{bmatrix}.\]
  </li>
  <li>
    <p><strong>Perifocal (PQW) Velocity:</strong></p>

\[\mathbf{v}_{PQW} = \begin{bmatrix}
-\sqrt{\dfrac{\mu}{p}}\,\sin\nu \\[1mm]
\sqrt{\dfrac{\mu}{p}}\,(e+\cos\nu) \\[1mm]
0
\end{bmatrix}.\]
  </li>
  <li>
    <p><strong>Transformation to the Inertial Frame:</strong></p>

\[\mathbf{r}_{ECI} = Q_{Xx}\,\mathbf{r}_{PQW},\quad \mathbf{v}_{ECI} = Q_{Xx}\,\mathbf{v}_{PQW},\]

    <p>where the rotation matrix \(Q_{Xx}\) incorporates rotations by \(-\omega\), \(-i\), and \(-\Omega\).</p>
  </li>
</ol>

<p>This complete derivation demonstrates how the Keplerian elements define a conic (elliptical) orbit and how to mathematically convert that description into the Cartesian state vector needed for numerical trajectory prediction.</p>]]></content><author><name></name></author><category term="space" /><category term="orbital-mechanics" /><summary type="html"><![CDATA[In a simple two-body problem where two bodies have finite mass, their trajectories in space follow an elliptical orbit. When the mass of one body is much larger than that of the other, \(m_1 \gg m_2\), we can approximate the larger body as stationary while the smaller body orbits around it. The trajectory of the smaller body can be modeled with either the Keplerian or Cartesian reference frames, each offering its own advantages. The Cartesian reference frame is particularly useful for numerical calculations—such as computing future trajectories given the current state—while the Keplerian frame provides a more intuitive understanding of the orbit by describing its phase space in mathematical terms.]]></summary></entry><entry><title type="html">Reasoning and RL for Large Language Models</title><link href="http://localhost:4000/machine-learning/reinforcement-learning/2025/02/12/grpo.html" rel="alternate" type="text/html" title="Reasoning and RL for Large Language Models" /><published>2025-02-12T00:00:00+08:00</published><updated>2025-02-12T00:00:00+08:00</updated><id>http://localhost:4000/machine-learning/reinforcement-learning/2025/02/12/grpo</id><content type="html" xml:base="http://localhost:4000/machine-learning/reinforcement-learning/2025/02/12/grpo.html"><![CDATA[<p>When we first think of reinforcement learning in the context of machine learning, we usually think of a grid with a start and end point. This is the standard reinforcement learning problem of teaching an agent to reach its goal using a clearly defined reward function. While reinforcement learning techniques have been existed for decades, its use for natural language processing (NLP) is fairly more recent, with arguably the most successful use case being to train ChatGPT. It is due to the lack of a clear reward that has led to this time gap between the formulation of such methods and its use to train language models. OpenAI solved this gap in part due to the power of belief and capitalism. The belief that such models can scale, and the capital from investors(at a scale largley unavailable to academics) to hire human evaluators to label data that it would eventually be used in its now well known reinforcement learning with human feedback (RLHF) algorithm.</p>

<p>The introduction of reasoning methods marks another paradigm shift in the way computation is performed using large language models. This has resulted in another form of scaling laws, moving away from improving performance at training time to inference time scaling. To reason is to be able to think logically in a series of sequential steps. Like walking step by step through a grid to get to a goal, reasoning is a natural complement that works well with reinforcement learning.</p>

<p>Reasoning was first introduced into the mainstream with ChatGPT o1, where reasoning tokens were generated as part of the output. The more tokens were generated, the higher quality the model would perform in benchmarks, in particular those related to math and coding. This also has a nice analogy/mapping back to the classic space-time tradeoff for computing. With a high amount of storage, less compute is needed to solve a problem. If computing can be done on the fly, then less storage is needed. This is also apt in another sense, since pretraining neural networks has also been shown as a compression/storage technique. The prompts/inputs to the LLM can be thought of as a key or unique identifier, and when paired with the compressed LLM it is able to decompress a lossy version of the training data.</p>

<p>Previous LLMs could reason in a adhoc sense using basic prompt engineering techniques like asking the model to ‘think step by step’. However, o1 was one of the first models where reasoning was part of training the model. A further breakthrough came with the introduction of deepseek r1, a reasoning model with open sourced code. One of the key innovations of the deepseek model is the Group Relative Policy Optimization (GRPO) algorithm, which removes the need for training the critic network that is typically a part of the Proximal Policy Optimization (PPO) used to train previous LLMs.</p>

<p>In this post, I will first introduce the various reinforcement learning notations that are used in the context of NLP, followed by going through the classic PPO objective followed by GRPO introduced by deepseek.</p>

<h2 id="rl-definitions-in-an-nlp-context">RL Definitions in an NLP Context</h2>

<p>Before diving into PPO and GRPO, we first defined the various notations used in the context of reinforcement learning for LLMs:</p>

<ul>
  <li>
    <p><strong>Prompt (\(q\))</strong>: The initial user input providing context for generation (can be denoted as \(q_t\) if dynamic).</p>
  </li>
  <li>
    <p><strong>State (\(s_t\))</strong>: The combination of the prompt and all tokens generated so far, i.e., 
\(s_t = (q, o_{&lt;t})\)</p>
  </li>
  <li>
    <p><strong>Action (\(o_t\))</strong>: The next token generated by the model at time \(t\).</p>
  </li>
  <li>
    <p><strong>Reward (\(r_t\))</strong>: A numerical score indicating how “good” the chosen token or sequence is (can be step-level or sequence-level).</p>
  </li>
  <li>
    <p><strong>Policy (\(\pi_\theta\))</strong>: The mapping from state \(s_t\) to a probability distribution over the next token; effectively, the LLM parameterized by \(\theta\).</p>
  </li>
  <li>
    <p><strong>Discount Factor (\(\gamma\))</strong>: Weights future rewards relative to immediate ones. For example, with \(\gamma=0.9\), rewards are discounted by 10% per time step.</p>
  </li>
  <li>
    <p><strong>GAE Parameter (\(\lambda\))</strong>: Balances bias and variance in advantage estimation by controlling how much future rewards influence the advantage calculation (higher \(\lambda\) includes more future rewards).</p>
  </li>
</ul>

<h2 id="proximal-policy-optimization">Proximal Policy Optimization</h2>

<p>The PPO surrogate objective is given by:</p>

\[\begin{aligned}
J_{\text{PPO}}(\theta)
&amp;= \mathbb{E}_{q \sim P(Q),\, o \sim \pi_{\theta}^{\text{old}}(\cdot \mid q)}
\Biggl[
  \frac{1}{|o|} \sum_{t=1}^{|o|}
  \min\Bigl\{
    \frac{\pi_\theta(o_t \mid q,\,o_{&lt;t})}{\pi_{\theta}^{\text{old}}(o_t \mid q,\,o_{&lt;t})} \, A_t,\; \\[1mm]
&amp;\quad
    \text{clip}\Bigl(
      \frac{\pi_\theta(o_t \mid q,\,o_{&lt;t})}{\pi_{\theta}^{\text{old}}(o_t \mid q,\,o_{&lt;t})},\; 1-\epsilon,\; 1+\epsilon
    \Bigr)\,A_t
  \Bigr\}
\Biggr]
\end{aligned}\]

<p>We can first go through this equation term by term in the context of natural language processing (NLP) to gain better insight into how PPO works. We start with the policy:</p>

\[\pi_\theta(o_t \mid q, o_{&lt;t})\]

<p>For NLP, the policy \(\pi_\theta\) is determined by a neural network (typically based on the transformer architecture). The network takes in \(t-1\) input tokens of the sequence \(o\) along with the prompt \(q\) to predict the \(t^{th}\) token, denoted by \(o_t\). For simplicity, we assume each word is a token.</p>

<p>Given a prompt \(q\) such as “What is the capital of France?”, the policy model \(\pi_\theta\) begins by predicting the first token \(o_1\), which could be “The”. The model then generates subsequent tokens based on the prompt and the previously generated tokens. The ratio</p>

\[\frac{\pi_\theta(o_t \mid q, o_{&lt;t})}{\pi_{\theta}^{\text{old}}(o_t \mid q, o_{&lt;t})}\]

<p>measures how much more likely the new policy is to predict the token \(o_t\) compared to the old policy. This ratio acts as a weight for the advantage \(A_t\), which we elaborate on next.</p>

<p>For PPO, the advantage \(A_t\) can be expressed as</p>

\[A_t = \sum_{l=0}^{T-t-1} (\gamma \lambda)^l \left[ Q(s_{t+l}, o_{t+l}) - V(s_{t+l}) \right]\]

<p>Here, \(Q(s_t, o_t)\) represents the cumulative reward after outputting \(o_t\). It is the sum of the immediate reward for predicting that token, denoted by \(r_t\), and the discounted sum of future rewards determined by the value network. In practice, we approximate</p>

\[Q(s_t, o_t) \approx r_t + \gamma\, V(s_{t+1})\]

<p>Thus, the temporal-difference error is given by</p>

\[\delta_t = Q(s_t, o_t) - V(s_t) = r_t + \gamma\, V(s_{t+1}) - V(s_t)\]

<p>The value network itself is trained using the loss function:</p>

\[L_V = \frac{1}{2}\,\mathbb{E}_t\left[\left(V_\psi(s_t)-R_t\right)^2\right],\]

<p>where \(R_t\) is the true expected sum of the discounted future rewards:</p>

\[R_t = r_t + \gamma\, r_{t+1} + \gamma^2\, r_{t+2} + \cdots + \gamma^{T-t}\, r_T.\]

<p>From these definitions, the advantage quantifies the difference between the cumulative reward received for the current action (which in the case of NLP is the token generated) and the reward that was expected according to the value network. A positive advantage means that the token performed better than expected, while a negative advantage indicates it performed worse.</p>

<p>Intuitively, having a positive advantage implies that the policy is outputting a better token than expected, which is what we want to optimize. Returning to our PPO equation, the advantage is used in two terms:</p>

<ul>
  <li>
    <p>The first term,</p>

\[\frac{\pi_\theta(o_t \mid q, o_{&lt;t})}{\pi_{\theta}^{\text{old}}(o_t \mid q, o_{&lt;t})} A_t,\]

    <p>ensures that the new policy does not deviate too much from the old policy, preserving the beneficial properties of the old policy.</p>
  </li>
  <li>
    <p>The second term,</p>

\[\text{clip}\!\left(\frac{\pi_\theta(o_t \mid q, o_{&lt;t})}{\pi_{\theta}^{\text{old}}(o_t \mid q, o_{&lt;t})},\, 1-\epsilon,\, 1+\epsilon\right) A_t,\]

    <p>prevents any single token from being overly rewarded by capping the ratio, ensuring that updates remain stable and do not lead to drastic changes.</p>
  </li>
</ul>

<p>Together, these terms form the PPO surrogate objective, which trains the network to optimize the cumulative reward for the next token while enforcing constraints that prevent large deviations from the previous policy. We can next move on to describe Group Relative Policy Optimization (GRPO) which was introduced by DeepSeek in their DeepSeekMath paper and how it improves upon PPO.</p>

<h2 id="group-relative-policy-optimization">Group Relative Policy Optimization</h2>

<p>The GRPO surrogate objective is given by:</p>

\[\begin{aligned}
\mathcal{J}_{\text{GRPO}}(\theta)
&amp;= \mathbb{E}_{\substack{q \sim P(Q), \\ \{o_i\}_{i=1}^{G} \sim \pi_{\theta}^{\text{old}}(\cdot \mid q)}}
\Biggl[
  \frac{1}{G} \sum_{i=1}^{G} \frac{1}{|o_i|} \sum_{t=1}^{|o_i|}
  \Biggl\{
    \min \Biggl(
      \frac{\pi_\theta\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}{\pi_{\theta}^{\text{old}}\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}
      \,\hat{A}_{i,t}, \\
&amp;\quad
      \text{clip}\Biggl(
        \frac{\pi_\theta\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}{\pi_{\theta}^{\text{old}}\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)},
        1-\epsilon,\,1+\epsilon
      \Biggr)\,\hat{A}_{i,t}
    \Biggr)
    \;-\;
    \beta\, D_{\mathrm{KL}}\bigl[\pi_\theta \,\|\, \pi_{\mathrm{ref}}\bigr]
  \Biggr\}
\Biggr]
\end{aligned}\]

<p>From the equation above we can see some differences compared to the PPO objective.  There is an additional sum across \(G\) actions \(o_i\) drawn from the old policy denoted by</p>

\[\{ o_i \}_{i=1}^{G} \sim \pi_{\theta}^{\text{old}}(\cdot \mid q)\]

<p>which is also expressed as a summation over \(G\) in the equation. There is also an additional KL divergence term \(D_{KL}\) which is measures the difference in policy distribution between the new policy and a reference policy, where</p>

\[D_{\mathrm{KL}}\!\bigl[\pi_\theta \,\|\, \pi_{\mathrm{ref}}\bigr]
\;=\;
\frac{\pi_{\mathrm{ref}}\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}{\pi_{\theta}\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}
\;-\;
\log \frac{\pi_{\mathrm{ref}}\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}{\pi_{\theta}\bigl(o_{i,t} \mid q,\,o_{i,&lt;t}\bigr)}
\;-\;1.\]]]></content><author><name></name></author><category term="machine-learning" /><category term="reinforcement-learning" /><category term="python" /><category term="llms" /><category term="generative ai" /><summary type="html"><![CDATA[When we first think of reinforcement learning in the context of machine learning, we usually think of a grid with a start and end point. This is the standard reinforcement learning problem of teaching an agent to reach its goal using a clearly defined reward function. While reinforcement learning techniques have been existed for decades, its use for natural language processing (NLP) is fairly more recent, with arguably the most successful use case being to train ChatGPT. It is due to the lack of a clear reward that has led to this time gap between the formulation of such methods and its use to train language models. OpenAI solved this gap in part due to the power of belief and capitalism. The belief that such models can scale, and the capital from investors(at a scale largley unavailable to academics) to hire human evaluators to label data that it would eventually be used in its now well known reinforcement learning with human feedback (RLHF) algorithm.]]></summary></entry><entry><title type="html">Decision Tree Regressors</title><link href="http://localhost:4000/machine-learning/regression/2024/12/20/decision-tree-regressor.html" rel="alternate" type="text/html" title="Decision Tree Regressors" /><published>2024-12-20T00:00:00+08:00</published><updated>2024-12-20T00:00:00+08:00</updated><id>http://localhost:4000/machine-learning/regression/2024/12/20/decision-tree-regressor</id><content type="html" xml:base="http://localhost:4000/machine-learning/regression/2024/12/20/decision-tree-regressor.html"><![CDATA[<p>Most people practicing data science would be aware of tree based learning methods like XGBoost.
Despite LLMs occupying the current spotlight, these tree based methods are still widely used and even <a href="https://arxiv.org/pdf/2207.08815">outperform neural networks</a> when dealing with tabular/structured data.</p>

<p>Neural networks, while powerful in their own right, excel at modelling unstructured data through their architecture, be it positional encoding + self-attention for seq2seq models or convolutions for images.
Tabular data still forms a large part of most companies’ data source and building models that leverage such data can yield great value through recommendation systems and targeted marketing campaigns.</p>

<p>I have always been interested in learning about the inner workings of such tree based methods, and will explain them in detail, starting with the decision tree regressor which is the foundation for tree based methods. While learning and writing on this topic I came across and was inspired by a useful <a href="https://randomrealizations.com/">blog</a> that helped me gain an intuitive understanding on these methods.</p>

<p>Before diving in to decision tree regressors, what is a regressor? A regressor is a trained model that learns a function which returns or outputs a continuous variable based on a given input. For example, a regressor can learn a simple linear function y = 2x. Inputting a value of 5 to this regressor would yield a value of 10 as the target output.</p>

<hr />

<h2 id="overview">Overview</h2>

<p>How do we estimate a function? Given a set of training data inputs X and label y we can assign mean(y) for any value of X.</p>

\[f(x) = mean(y)\]

<p>We can extend this further to apply thresholds at certain values of \(x\) where</p>

\[f(x&lt;n) = mean(y\mid x &lt;n)\]

<p><img src="/images/binarytree.jpg" alt="Alt text" /></p>

<p>This can also be illustrated with the binary tree above, where the threshold n=0. If \(x\) is less than 0, the model predicts y=0.15 and it predicts y=0.85 for any value greater or equal to 0. The binary tree above shows one threshold value with depth=1. We can illustrate this example more clearly when fitting a decision tree regressor of various depths to a sigmoid function: \(y = \frac{1}{1 + e^{-x}}\).</p>

<p><img src="/images/scatter.jpg" alt="An example image" /></p>

<p>From the image above we can see how well our decision tree regressor fits the sigmoid function at various depths of the tree. Depth=0 is denoted by the green line where we naively assume that any value x will approximate the mean of y. For depth=1 we can see a threshold at \(x=0\) and gradually see our model increasingly fit the sigmoid function with increasing depth.</p>

<hr />

<h2 id="code-explained">Code Explained</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="k">else</span> <span class="mf">0.0</span>

<span class="k">def</span> <span class="nf">variance</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nf">sum</span><span class="p">((</span><span class="n">i</span> <span class="o">-</span> <span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div></div>

<p>Before going through the decision tree regressor line by line we first define two helper functions to obtain the mean and variance. Mean is used to determine the approximate value at each threshold, while variance (also known as mean square error) determines which threshold we use.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">root</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">stack</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span> <span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">:</span> <span class="n">root</span><span class="p">}]</span>

<span class="n">current</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
<span class="n">Xc</span><span class="p">,</span> <span class="n">yc</span> <span class="o">=</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">],</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">]</span>
<span class="n">depth</span><span class="p">,</span> <span class="n">node</span> <span class="o">=</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">],</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">]</span>

<span class="nf">if </span><span class="p">(</span><span class="n">depth</span> <span class="o">==</span> <span class="n">max_depth</span>
    <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_samples_split</span>
    <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">yc</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
    <span class="k">continue</span>
</code></pre></div></div>
<p>We initialize root, which is the top node of the decision tree, and stack, which keeps track of the nodes of the decision tree and their associated depths. When the maximum depth is reached or the target values at a node contain only one unique value, the mean of the target values is assigned as the node’s value.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">parent_var</span> <span class="o">=</span> <span class="nf">variance</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
<span class="n">best_feat</span><span class="p">,</span> <span class="n">best_thresh</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
<span class="n">best_gain</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">"</span><span class="s">-inf</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p>Next we let the existing variance before splitting be the variance of all the labels for that parent node. We also initialise the best input feature, best threshold and best gain. Gain would be a measure and decider on whether to use a certain input index as a threshold.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">Xc</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Xc</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
        <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">({</span><span class="n">row</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">Xc</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
            <span class="n">left_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">]</span>
            <span class="n">right_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">]</span>

            <span class="c1"># If one side is empty, ignore this split
</span>            <span class="k">if</span> <span class="ow">not</span> <span class="n">left_y</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">right_y</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">w</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">left_y</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
            <span class="n">child_var</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="nf">variance</span><span class="p">(</span><span class="n">left_y</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="nf">variance</span><span class="p">(</span><span class="n">right_y</span><span class="p">)</span>
            <span class="n">gain</span> <span class="o">=</span> <span class="n">parent_var</span> <span class="o">-</span> <span class="n">child_var</span>

            <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;</span> <span class="n">best_gain</span><span class="p">:</span>
                <span class="n">best_gain</span> <span class="o">=</span> <span class="n">gain</span>
                <span class="n">best_feat</span> <span class="o">=</span> <span class="n">f</span>
                <span class="n">best_thresh</span> <span class="o">=</span> <span class="n">t</span>
</code></pre></div></div>
<p>If the input set Xc is not empty, we iterate across all possible features and all input indices for that feature. For a data with 1-dimensional input features we simply iterate across all indices.
The input indices which results in the best gain would be kept as the thresholds.</p>

<p>Gain is defined as the difference between the variance of the target variables before the split and the weighted sum of the variance after the split.</p>

\[\text{Gain} = \sigma^2_{\text{parent}} - \left( \frac{N_L}{N} \cdot \sigma^2_L + \frac{N_R}{N} \cdot \sigma^2_R \right)\]

<p>Intuitively this means that the variance, also known as the mean square error is reduced compared to before the threshold was applied.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">best_feat</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">best_gain</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
    <span class="k">continue</span>

<span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">feature</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_feat</span>
<span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">threshold</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_thresh</span>
</code></pre></div></div>
<p>If no split is found that reduces gain, we let that node be a leaf. If the gain is reduced, we save the best features and threshold recorded.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">Xc</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">best_feat</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">best_thresh</span><span class="p">:</span>
        <span class="n">left_X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
        <span class="n">left_y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">right_X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
        <span class="n">right_y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Push stack to be processed next
</span><span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">:</span> <span class="n">left_X</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">left_y</span><span class="p">,</span> <span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">:</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">]})</span>
<span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">:</span> <span class="n">right_X</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">right_y</span><span class="p">,</span> <span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">:</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">]})</span>
</code></pre></div></div>
<p>Finally, we update the tree with the new threshold found and split the tree according to the new threshold. We record this into the stack.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>

    <span class="n">root</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">stack</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span> <span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">:</span> <span class="n">root</span><span class="p">}]</span>

    <span class="k">while</span> <span class="n">stack</span><span class="p">:</span>
        <span class="n">current</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
        <span class="n">Xc</span><span class="p">,</span> <span class="n">yc</span> <span class="o">=</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">],</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">depth</span><span class="p">,</span> <span class="n">node</span> <span class="o">=</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">],</span> <span class="n">current</span><span class="p">[</span><span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">]</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="sh">'</span><span class="s">node</span><span class="sh">'</span><span class="p">)</span>
        <span class="c1"># Stopping conditions: depth reached, insufficient samples, or all targets identical
</span>        <span class="nf">if </span><span class="p">(</span><span class="n">depth</span> <span class="o">==</span> <span class="n">max_depth</span>
            <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_samples_split</span>
            <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">yc</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># Compute parent variance for this node
</span>        <span class="n">parent_var</span> <span class="o">=</span> <span class="nf">variance</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>

        <span class="c1"># Find best split across all features/thresholds
</span>        <span class="n">best_feat</span><span class="p">,</span> <span class="n">best_thresh</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
        <span class="n">best_gain</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">"</span><span class="s">-inf</span><span class="sh">"</span><span class="p">)</span>

        <span class="c1"># If Xc is empty, skip
</span>        <span class="k">if</span> <span class="n">Xc</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Xc</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">({</span><span class="n">row</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">Xc</span><span class="p">})</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
                    <span class="n">left_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">]</span>
                    <span class="n">right_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">]</span>

                    <span class="c1"># If one side is empty, ignore this split
</span>                    <span class="k">if</span> <span class="ow">not</span> <span class="n">left_y</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">right_y</span><span class="p">:</span>
                        <span class="k">continue</span>

                    <span class="n">w</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">left_y</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
                    <span class="n">child_var</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="nf">variance</span><span class="p">(</span><span class="n">left_y</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="nf">variance</span><span class="p">(</span><span class="n">right_y</span><span class="p">)</span>
                    <span class="n">gain</span> <span class="o">=</span> <span class="n">parent_var</span> <span class="o">-</span> <span class="n">child_var</span>

                    <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;</span> <span class="n">best_gain</span><span class="p">:</span>
                        <span class="n">best_gain</span> <span class="o">=</span> <span class="n">gain</span>
                        <span class="n">best_feat</span> <span class="o">=</span> <span class="n">f</span>
                        <span class="n">best_thresh</span> <span class="o">=</span> <span class="n">t</span>

        <span class="c1"># If no meaningful split was found, make this node a leaf
</span>        <span class="k">if</span> <span class="n">best_feat</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">best_gain</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">yc</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># Record the chosen feature &amp; threshold
</span>        <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">feature</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_feat</span>
        <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">threshold</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_thresh</span>

        <span class="c1"># Partition data into left/right subsets
</span>        <span class="n">left_X</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">left_y</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">right_X</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">right_y</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">Xc</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">best_feat</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">best_thresh</span><span class="p">:</span>
                <span class="n">left_X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
                <span class="n">left_y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">right_X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
                <span class="n">right_y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">yc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># Initialize child nodes
</span>        <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Push them to be processed next
</span>        <span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">:</span> <span class="n">left_X</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">left_y</span><span class="p">,</span> <span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">:</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">]})</span>
        <span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">"</span><span class="s">X</span><span class="sh">"</span><span class="p">:</span> <span class="n">right_X</span><span class="p">,</span> <span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">:</span> <span class="n">right_y</span><span class="p">,</span> <span class="sh">"</span><span class="s">depth</span><span class="sh">"</span><span class="p">:</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">node</span><span class="sh">"</span><span class="p">:</span> <span class="n">node</span><span class="p">[</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">]})</span>

    <span class="k">return</span> <span class="n">root</span>
</code></pre></div></div>

<p>We can combine this all we just discussed into a function train_tree that iterates recursively until the stopping criteria is reached. Where the stopping criteria is defined as max depth of tree, insufficient samples or identical targets at a node.</p>

<h2 id="example-implementation">Example Implementation</h2>
<p>We can implement this on a simple example with input data X as some discrete values and target variable y as the sigmoid function applied to X.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.01</span><span class="o">*</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="o">-</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> 
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span> 
<span class="n">tree</span> <span class="o">=</span> <span class="nf">train_tree</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
<span class="p">{</span><span class="sh">'</span><span class="s">feature</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">threshold</span><span class="sh">'</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.21409955507181783</span><span class="p">},</span> <span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.7849506095629721</span><span class="p">}}</span>
</code></pre></div></div>

<p>By training the tree on a sigmoid distribution with depth=1, we can see that the threshold of \(-0.01 \approx 0\) which is denoted by the green line in our earlier plot as the sigmoid function is symmetric. This acts as a sanity test and also shows the structure of the decision tree regressor as well as how it works after training. If the input value is less than the threshold, the model will return the left value, and the right value otherwise.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
    <span class="c1"># If this node is a leaf, return its value
</span>    <span class="k">if</span> <span class="sh">"</span><span class="s">value</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">tree</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tree</span><span class="p">[</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">]</span>
    
    <span class="c1"># Otherwise, compare the sample's feature to the threshold
</span>    <span class="k">if</span> <span class="n">sample</span><span class="p">[</span><span class="n">tree</span><span class="p">[</span><span class="sh">"</span><span class="s">feature</span><span class="sh">"</span><span class="p">]]</span> <span class="o">&lt;=</span> <span class="n">tree</span><span class="p">[</span><span class="sh">"</span><span class="s">threshold</span><span class="sh">"</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nf">predict</span><span class="p">(</span><span class="n">tree</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">],</span> <span class="n">sample</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nf">predict</span><span class="p">(</span><span class="n">tree</span><span class="p">[</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">],</span> <span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<p>We can write a predict function above to recursively propagate the input value across the branches of the tree till it reaches a node.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">predict</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">7</span><span class="p">])</span>
<span class="mf">0.21409955507181783</span>
<span class="nf">predict</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="p">[</span><span class="mi">7</span><span class="p">])</span>
<span class="mf">0.7849506095629721</span>
</code></pre></div></div>

<p>Using positive and negative values for a simple trained tree depth=1 we can the different predicted values depending on whether the input is above or below the threshold we have derived.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Decision tree regressors offer an intuitive way to model continuous target values through sequential splitting on feature thresholds. By measuring the reduction in variance (or mean squared error) at each potential split, we iteratively build a tree that partitions the input space into regions with relatively homogeneous target values. While simple to conceptualise and implement, this foundation underpins more sophisticated models commonly used in data science, such as gradient boosted machines and xgboost. With an understanding of how a single decision tree regressor is constructed, we can have a greater appreciation of these models beyond viewing them as sklearn functions or blackboxes.</p>

<h2 id="references">References</h2>
<ol>
  <li><a href="https://arxiv.org/pdf/2207.08815">Why do tree-based models still outperform deep learning on tabular data?</a></li>
  <li><a href="https://randomrealizations.com/posts/gradient-boosting-machine-from-scratch/">How to Build a Gradient Boosting Machine from Scratch</a></li>
</ol>]]></content><author><name></name></author><category term="machine-learning" /><category term="regression" /><category term="decision-trees" /><category term="python" /><summary type="html"><![CDATA[Most people practicing data science would be aware of tree based learning methods like XGBoost. Despite LLMs occupying the current spotlight, these tree based methods are still widely used and even outperform neural networks when dealing with tabular/structured data.]]></summary></entry></feed>